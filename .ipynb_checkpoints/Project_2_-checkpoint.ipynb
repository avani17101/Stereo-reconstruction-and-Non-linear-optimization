{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "## Topic : Stereo reconstruction and Non-linear optimization\n",
    "\n",
    "#### Instructions\n",
    "<ul>\n",
    "    <li> The second project of the course is designed to get you familiar with stereo reconstruction, and non-linear optimization </li>\n",
    "    <li> Use python for this project. PILLOW and OpenCV are permitted for image I/O. </li>\n",
    "    <li> Submit this notebook as a zipped file on moodle. The format should be $<$team_id$>$_$<$team_ name$>$.zip. Both members have to submit this zip file. </li>\n",
    "    <li> A seperate report is not needed if you're coding in the notebook itself. Please provide adequate descriptions of the approaches you've taken. Also mention work distribution for the two members. </li>\n",
    "    <li> Refer to the late day policy. Start early </li> \n",
    "    <li> Download data from here: https://iiitaphyd-my.sharepoint.com/:f:/g/personal/aryan_sakaria_students_iiit_ac_in/Er5C7351IAlFsvwHUesFeSQBQtlSiAS7AORSEJT2qH_8_w?e=ol98k9  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 1: Stereo dense reconstruction\n",
    "\n",
    "3-D point clouds are very useful in robotics for several tasks such as object detection, motion estimation (3D-3D matching or 3D-2D matching), SLAM, and other forms of scene understanding.  Stereo camerasprovide  us  with  a  convenient  way  to  generate  dense  point  clouds.Densehere,  in  contrast  tosparse,means all the image points are used for the reconstruction.  In this part of the assignment you will begenerating a dense 3D point cloud reconstruction of a scene from stereo images.\n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Generate a disparity map for each stereo pair.  Use OpenCV (e.g.  StereoSGBM) for this.  Notethat the images provided are already rectified and undistorted. </li>\n",
    "    <li> Then, using the camera parameters and baseline information generate colored point clouds fromeach disparity map.  Some points will have invalid disparity values, so ignore them.  Use [Open3D]for storing your point clouds. </li>\n",
    "    <li> Register (or transform) all the generated point clouds into your world frame by using the providedground truth poses. </li>\n",
    "    <li> Visualize the registered point cloud data, in color.  Use Open3D for this </li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries:\n",
    "import numpy as np \n",
    "# from sklearn.preprocessing import normalize #normalizing gives better results. Experiment with this\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transformations(filename='data/poses.txt'):\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    transformation_list = []\n",
    "    for i in range(len(lines)):\n",
    "        transformation_list_temp = lines[i].split()\n",
    "        temp_rot = [] \n",
    "        temp_rot.append( (transformation_list_temp[0:4] ) ) \n",
    "        temp_rot.append( (transformation_list_temp[4:8]  ) ) \n",
    "        temp_rot.append( (transformation_list_temp[8:12]  ) ) \n",
    "        transformation_list.append(temp_rot)\n",
    "    return transformation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide explanation in this cell: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose shape (21, 3, 4)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-89914e00452b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0mQ_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0mdisp_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mPixel_Point_Map_alt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0mPixel_Point_Map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0mPixel_Point_Map_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "      \n",
    "transformation_list = read_transformations()\n",
    "def convertToint(transformation_list):\n",
    "    int_tl = []\n",
    "    for i in range(len(transformation_list)):\n",
    "        for j in range(len(transformation_list[i])):\n",
    "            for k in range(len(transformation_list[i][j])):\n",
    "                int_tl.append(float(transformation_list[i][j][k]))\n",
    "    return np.array(int_tl).reshape((21, 3, 4))\n",
    "\n",
    "def getfiles():\n",
    "    lst = os.listdir('./data/img2')\n",
    "    images = sorted(lst)[0:1]\n",
    "    return images\n",
    "imgs = getfiles()\n",
    "\n",
    "pose = convertToint(transformation_list)\n",
    "print(\"pose shape\",pose.shape)\n",
    "\n",
    "def combinePoses(pose):\n",
    "    combi = []\n",
    "    combi.append(np.vstack([pose[0], np.array([0, 0, 0, 1])]))\n",
    "    for c in range(1, len(pose)):\n",
    "        combi.append(np.vstack([pose[c], np.array([0, 0, 0, 1])]))\n",
    "    return combi\n",
    "combi = combinePoses(pose)\n",
    "\n",
    "def create3d_point(pt, combi):\n",
    "    P = []\n",
    "    pts = []\n",
    "    for i in range(3):\n",
    "        P.append([combi[i][0], combi[i][1], combi[i][2], combi[i][3]])\n",
    "        pts.append(pt[i])\n",
    "    \n",
    "    P = np.array(P)\n",
    "    pts.append(1)\n",
    "    pts = np.array(pts)\n",
    "    pts = pts.T\n",
    "    return np.matmul(P, pts)\n",
    "\n",
    "def write_ply(vertices, colors, filename):  #taken from github\n",
    "    ply_header = '''ply\n",
    "        format ascii 1.0\n",
    "        element vertex %(vert_num)d\n",
    "        property float x\n",
    "        property float y\n",
    "        property float z\n",
    "        property uchar red\n",
    "        property uchar green\n",
    "        property uchar blue\n",
    "        end_header\n",
    "        '''\n",
    "    colors = colors.reshape(-1,3)\n",
    "    vertices = np.hstack([vertices.reshape(-1,3),colors])\n",
    "\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(ply_header %dict(vert_num=len(vertices)))\n",
    "        np.savetxt(f,vertices,'%f %f %f %d %d %d')\n",
    "        \n",
    "def displarity(iml,imr):\n",
    "    \n",
    "    win_size = 3\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = 16,\n",
    "       P1 = 8*3*win_size**2,\n",
    "       blockSize = 7,\n",
    "       numDisparities = 112-16+(2) * 16,\n",
    "       speckleWindowSize = 400,\n",
    "       speckleRange = 5,\n",
    "       disp12MaxDiff = 1,\n",
    "       uniquenessRatio = 12,\n",
    "      P2 = 32*3*win_size**2,)\n",
    "#     stereo = cv2.StereoSGBM_create(numDisparities=16, blockSize=15)\n",
    "    disp_map = stereo.compute(iml, imr).astype(np.float32) / 16.0\n",
    "    return disp_map\n",
    "\n",
    "def get_images(img):\n",
    "    \"\"\"\n",
    "    Returns left and right images\n",
    "    \"\"\"\n",
    "    return cv2.imread('./data/img2/' + img), cv2.imread('./data/img3/' + img)\n",
    "\n",
    "def getk(f=7.070912e+02):\n",
    "    k = np.zeros((3,3))\n",
    "    k[0][0] = f\n",
    "    k[1][1] = f\n",
    "    k[0][2] = 6.018873e+02\n",
    "    k[1][2] = 1.831104e+02\n",
    "    k[2][2] = 1\n",
    "  \n",
    "    return k.astype(np.float32)\n",
    "\n",
    "def get_q(w,h,f = 7.070912e+02,baseline = 0.53790448812):\n",
    "    # Form Q matrix to reproject back into 3d\n",
    "    Q = np.zeros((4,4))\n",
    "    Q[0][0] = 1\n",
    "    Q[0][3] = -0.5*w\n",
    "    Q[1][1] = -1\n",
    "    Q[1][3] =  0.5*h\n",
    "    Q[2][3] = -f\n",
    "    Q[3][2] = -1/baseline\n",
    "    \n",
    "#     Q = [[1, 0, 0, -0.5*w],\n",
    "#         [0,-1, 0,  0.5*h], \n",
    "#         [0, 0, 0, -f], \n",
    "#         [0, 0, -1/baseline,  0]]\n",
    "\n",
    "    return Q.astype(np.float32)\n",
    "    \n",
    "def get3d(disp_map,Q,iml):\n",
    "    points = cv2.reprojectImageTo3D(disp_map, Q)\n",
    "    colors = cv2.cvtColor(iml, cv2.COLOR_BGR2RGB)\n",
    "    return points, colors\n",
    "\n",
    "def transform_by_GT(output_points,output_colors,count):\n",
    "    final_output = []\n",
    "    final_color = []\n",
    "    for i,pt in enumerate(output_points):\n",
    "        final_output.append(np.array(create3d_point(pt, combi[count]).T))\n",
    "        final_color.append(output_colors[i])\n",
    "    return np.array(final_output).astype('float32')[0], np.array(final_color)\n",
    "\n",
    "def recover3D(pt_temp,points,counts):\n",
    "    pt = [pt_temp[0]/pt_temp[3], pt_temp[1]/pt_temp[3], pt_temp[2]/pt_temp[3]]\n",
    "    points[i][j] = pt\n",
    "    Pixel_Point_Map[count+start].append(([i, j], pt))\n",
    "    return points, Pixel_Point_Map\n",
    "\n",
    "def pixtoworld(disp_map, Q, iml, count, Pixel_Point_Map, Pixel_Point_Map_alt, Pixel_Point_Map_2, points ):\n",
    "    \n",
    "    Pixel_Point_Map_alt[count] = []\n",
    "    Pixel_Point_Map[count] = []\n",
    "    Pixel_Point_Map_2[count] = []\n",
    "    \n",
    "    start = 0\n",
    "    for i in range(len(iml)):\n",
    "        for j in range(len(iml[i])):\n",
    "            \n",
    "            min_disp = disp_map.min()\n",
    "            pt_temp = np.multiply(Q,np.array([i, j, disp_map[i][j]/16.0, 1]).T)\n",
    "            points, Pixel_Point_Map = recover3D(pt_temp,points,counts)\n",
    "            \n",
    "            if disp_map[i][j] > min_disp:\n",
    "                Pixel_Point_Map_alt[count+start].append(([i, j], to_ap))\n",
    "                pt_new_temp = np.array(create3d_point(to_ap, combi[count+start]).T)\n",
    "                Pixel_Point_Map_2[count+start].append(([i, j], [pt_new_temp[0], pt_new_temp[1], pt_new_temp[2]]))\n",
    "    \n",
    "    return Pixel_Point_Map, Pixel_Point_Map_alt,Pixel_Point_Map_2\n",
    "        \n",
    "global final_output, final_color, output_colors, output_points, disp_map\n",
    "k = getk()\n",
    "Q_list = []\n",
    "disp_list = []\n",
    "Pixel_Point_Map_alt = {}\n",
    "Pixel_Point_Map = {}\n",
    "Pixel_Point_Map_2 = {}\n",
    "\n",
    "for count, img in enumerate(imgs):\n",
    "    iml, imr = get_images(img)\n",
    "    disp_map = displarity(iml,imr)\n",
    "    disp_list.append(disp_map)\n",
    "    h, w = iml.shape[:2]\n",
    "    Q = get_q(w,h)\n",
    "    Q_list.append(Q)\n",
    "    points, colors = get3d(disp_map,Q,iml)\n",
    "    Pixel_Point_Map, Pixel_Point_Map_alt,Pixel_Point_Map_2 = pixtoworld(disp_map, Q, iml, count,Pixel_Point_Map, Pixel_Point_Map_alt, Pixel_Point_Map_2,points)\n",
    "    mask = disp_map > disp_map.min()\n",
    "    output_points = points[mask]\n",
    "    output_colors = colors[mask]\n",
    "    final_output, final_color = transform_by_GT(output_points,output_colors,count)\n",
    "    \n",
    "write_ply(final_output, final_color, 'out.ply')\n",
    "\n",
    "\n",
    "def visualize(filename):\n",
    "    pcd = o3d.io.read_point_cloud(filename)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "visualize('out.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import open3d as o3d\n",
    "\n",
    "# ply_header = '''ply\n",
    "# format ascii 1.0\n",
    "# element vertex %(vert_num)d\n",
    "# property float x\n",
    "# property float y\n",
    "# property float z\n",
    "# property uchar red\n",
    "# property uchar green\n",
    "# property uchar blue\n",
    "# end_header\n",
    "# '''\n",
    "\n",
    "# def write_ply(fn, verts, colors):\n",
    "#     #github lol\n",
    "#     verts = verts.reshape(-1, 3)\n",
    "#     colors = colors.reshape(-1, 3)\n",
    "#     verts = np.hstack([verts, colors])\n",
    "#     with open(fn, 'wb') as f:\n",
    "#         f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "#         np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')\n",
    "\n",
    "\n",
    "# def extract(file):\n",
    "#     transforms = []\n",
    "#     for i in range(0,21):\n",
    "#         line = file.readline()\n",
    "#         line = line.split()\n",
    "#         arr = np.array(line)\n",
    "#         arr = arr.reshape(3,4)\n",
    "#         transforms.append(arr)\n",
    "#         #Reads the poses text file.\n",
    "#     return transforms\n",
    "\n",
    "# txtfile = open(\"data/poses.txt\", \"r\")\n",
    "# transforms = extract(txtfile)\n",
    "# txtfile.close()\n",
    "\n",
    "\n",
    "# def make_new_pt(pt_3d, C):\n",
    "#     # Funtion to convert to 3d points in the world frame.\n",
    "#     P = np.array([\n",
    "#         [C[0][0], C[0][1], C[0][2], C[0][3]],\n",
    "#         [C[1][0], C[1][1], C[1][2], C[1][3]],\n",
    "#         [C[2][0], C[2][1], C[2][2], C[2][3]],\n",
    "#     ]).astype(np.float32)\n",
    "#     pt = np.mat([pt_3d[0], pt_3d[1], pt_3d[2], 1]).T.astype(np.float32)\n",
    "#     mat = np.matmul(P, pt)\n",
    "#     rotation = np.array([[-1, 0 , 0],\n",
    "#                         [ 0, 1, 0],\n",
    "#                         [ 0,  0, 1]])\n",
    "#     rotatedPoint = np.matmul(rotation, mat)\n",
    "#     #Aligning the coordinate frame of open3d with that of cv2\n",
    "#     return [rotatedPoint, rotatedPoint[2]]\n",
    "\n",
    "# def main():\n",
    "#     final_output = []\n",
    "#     final_color = []\n",
    "\n",
    "#     window_size = 5\n",
    "#     left_matcher = cv2.StereoSGBM_create(\n",
    "#         minDisparity = -39,\n",
    "#         numDisparities = 144,\n",
    "#         blockSize = 5,\n",
    "#         P1 = 8 * 3 * window_size ** 2,\n",
    "#         P2 = 64 * 3 * window_size ** 2,\n",
    "#         disp12MaxDiff = 1,\n",
    "#         uniquenessRatio = 10,\n",
    "#         speckleWindowSize = 100,\n",
    "#         speckleRange = 32,\n",
    "#         preFilterCap = 63\n",
    "#         )\n",
    "\n",
    "#     right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "#     wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher)\n",
    "#     wls_filter.setLambda(80000)\n",
    "#     wls_filter.setSigmaColor(1.3)\n",
    "\n",
    "#     for i in range(60,81):\n",
    "#         imgL = cv2.imread( \"data/img2/\" + \"00000004\" + str(i) + \".png\" , 0)\n",
    "#         imgR = cv2.imread( \"data/img3/\" + \"00000004\" + str(i) + \".png\"  , 0)\n",
    "#         imgL_c = cv2.imread(\"data/img2/\" + \"00000004\" + str(i) + \".png\" )\n",
    "\n",
    "\n",
    "#         left_disp = left_matcher.compute(imgL,imgR).astype(np.float32)\n",
    "#         right_disp = right_matcher.compute(imgR,imgL).astype(np.float32)\n",
    "#         left_disp = np.int16(left_disp)\n",
    "#         right_disp = np.int16(right_disp)\n",
    "\n",
    "#         Img_Filtered = wls_filter.filter(left_disp, imgL, None, right_disp)\n",
    "#         Img_Filtered = cv2.normalize(src=Img_Filtered, dst=Img_Filtered, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX).astype(np.float32);\n",
    "\n",
    "#         Img_Filtered = cv2.normalize(src = left_disp, dst = Img_Filtered, beta= 0, alpha = 255, norm_type = cv2.NORM_MINMAX).astype(np.float32)\n",
    "\n",
    "#         Img_Filtered = np.float32(Img_Filtered)/16.0\n",
    "#         #imgplot = plt.imshow(Img_Filtered)\n",
    "#         #plt.show()\n",
    "\n",
    "#         calib = np.array([ 7.215377000000e+02, 0.000000000000e+00, 6.095593000000e+02, 4.485728000000e+01,\n",
    "#                            0.000000000000e+00, 7.215377000000e+02, 1.728540000000e+02, 2.163791000000e-01,\n",
    "#                            0.000000000000e+00, 0.000000000000e+00, 1.000000000000e+00,2.745884000000e-03])\n",
    "\n",
    "#         P0 = calib.reshape((3,4))\n",
    "\n",
    "#         h, w = imgL.shape[:2]\n",
    "#         f = P0[0][0]\n",
    "#         B = 0.54\n",
    "#         #B = 0.53790448812\n",
    "#         Q = np.float32([[1, 0, 0, -P0[0][2]],\n",
    "#                         [0, 1, 0, -P0[1][2]], # turn points 180 deg around x-axis,\n",
    "#                         [0, 0, 0,  P0[0][0]], # so that y-axis looks up\n",
    "#                         [0, 0, -1/B,     0]])\n",
    "\n",
    "#         #Baseline matrix\n",
    "#         points = cv2.reprojectImageTo3D(Img_Filtered, Q, handleMissingValues = 1)\n",
    "#         colors = cv2.cvtColor(imgL_c, cv2.COLOR_BGR2RGB)\n",
    "#         mask = Img_Filtered > Img_Filtered[0][0]\n",
    "#         out_colors = colors[mask]\n",
    "#         out_points = points[mask]\n",
    "#         print(i)\n",
    "\n",
    "#         for j,pt in enumerate(out_points):\n",
    "\n",
    "#             pointProperties = make_new_pt(pt, transforms[i - 60])\n",
    "#             point3D = pointProperties[0].T\n",
    "#             depthWorldFrame = pointProperties[1]\n",
    "#             #Multiplying the reprojected points with the odometry poses to get the points in the world coordinate frame\n",
    "#             #The make new point returns the reprojected, transformed point as well as a paramter used for depth rejection to obtain a clean point cloud.\n",
    "#             if depthWorldFrame <= 200 and depthWorldFrame >= 69:\n",
    "#                 final_output.append(point3D)\n",
    "#                 final_color.append(out_colors[j])\n",
    "\n",
    "#     out_fn = \"finalRegistration.ply\"\n",
    "#     final_output = np.array(final_output)\n",
    "#     final_color = np.array(final_color)\n",
    "#     print(final_output.shape)\n",
    "#     print(final_color.shape)\n",
    "#     write_ply(out_fn, final_output, final_color)\n",
    "\n",
    "# main()\n",
    "\n",
    "# pcd = o3d.io.read_point_cloud(\"./finalRegistration.ply\")\n",
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 2: Motion estimation using iterative PnP\n",
    "\n",
    "Using the generated reconstruction from the previous part, synthesize a new image taken by a virtualmonocular camera fixed at any arbitrary position and orientation.  Your task in this part is to recoverthis pose using an iterative Perspective-from-n-Points (PnP) algorithm. \n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Obtain a set of 2D-3D correspondences between the the image and the point cloud.  Since hereyou’re generating the image, this should be easy to obtain. </li>\n",
    "    <li> For this set of correspondences compute the total reprojection error c= $\\sum_{i} ‖x_i−P_{k}X_i‖^2 $    where $P_{k}= K[R_{k}|t_{k}]$, $X_{i}$ is the 3D point in the world frame, $x_{i}$ is its corresponding projection. </li>\n",
    "    <li> Solve for the pose $T_{k}$ that minimizes this non-linear reprojection error using a Gauss-Newton (GN)scheme.  Recall that in GN we start with some initial estimated value $x_{o}$ and iteratively refine the estimate using $x_{1}$= $∆x+x_0$, where $∆x$ is obtained by solving the normal equations $J^{T}J∆x$= -$J^{T}e$, until convergence.The main steps in this scheme are computing the corresponding Jacobians and updating the estimates correctly.  For our problem,  use a 12×1 vector parameterization for $T_{k}$(the top 3×4submatrix).  Run the optimization for different choices of initialization and report your observations. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct projection matrix: \n",
      " [[-8.88191631e+02  5.41139423e+01 -2.46276119e+02 -1.55303217e+05]\n",
      " [-3.62607430e+01  7.13441345e+02 -1.49909078e+02  1.42607815e+02]\n",
      " [-4.12056509e-01  4.15693433e-02 -8.96946037e-01 -2.90293725e+01]]\n"
     ]
    }
   ],
   "source": [
    "def expected_proj_mat():\n",
    "    Q = np.array([ [-9.1e-01, 5.5e-02, -4.2e-01, -1.9e+02],\n",
    "                   [4.2e-02, 9.983072e-01, 4.2e-02, 1.7e+00],\n",
    "                   [4.2e-01, 2.1e-02, -9.2e-01, 5.5e+01] ])\n",
    "    Q=np.vstack((Q,np.array([0,0,0,1])))\n",
    "    Q=np.linalg.inv(Q)[:3, :]\n",
    "    cal_mat = [[7.070912e+02, 0.000000e+00, 6.018873e+02], \n",
    "               [0.000000e+00, 7.070912e+02, 1.831104e+02],\n",
    "               [0.000000e+00, 0.000000e+00, 1.000000e+00] ]\n",
    "    cal_mat = np.array(cal_mat)\n",
    "    P = np.matmul(cal_mat, Q) # 3x4 matrix \n",
    "    print(\"Correct projection matrix: \\n\", P)\n",
    "expected_proj_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squared sum error: 1118.6856271150302\n",
      "Predicted projection matrix: \n",
      "\n",
      "[[-8.80134111e+02  5.41373240e+01 -2.39692516e+02 -1.61421016e+05]\n",
      " [-3.47257393e+01  7.08694970e+02 -1.42921365e+02 -2.56840895e+03]\n",
      " [-4.22794749e-01  4.18964598e-02 -8.93047965e-01 -6.32525301e+01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def twodto3d(Pixel_Point_Map_alt,P):\n",
    "    pts_3d = [] \n",
    "    orig_pts_2d = [] \n",
    "    for i in range(0, 10000, 100): \n",
    "        pt_3d = np.append(Pixel_Point_Map_alt[0][i][1], 1) \n",
    "        pts_3d.append(pt_3d)\n",
    "        actual_pt_2d = P@pt_3d\n",
    "        orig_pts_2d.append(actual_pt_2d/actual_pt_2d[2])\n",
    "    return np.array(pts_3d), np.array(orig_pts_2d) \n",
    "\n",
    "pts_3d, orig_pts_2d = twodto3d(Pixel_Point_Map_alt,P)\n",
    "\n",
    "Proj_est = np.array([ [-8.8e+02,5.4e+01,-2.4e+02,-1.5e+05],\n",
    "                   [-3.6e+01,7.1e+02,-1.4e+02,1.4e+02],\n",
    "                   [-4.1e-01,4.1e-02,-8.9e-01,-2.9e+01] ])\n",
    "\n",
    "def get_err(orig_pts_2d, pts_2d):\n",
    "    sum_sq_error = 0\n",
    "    error = np.delete(orig_pts_2d - pts_2d, 2, axis=1)\n",
    "    return np.sum(np.square(e)) ,error\n",
    "\n",
    "def getJ(pts_3d, Proj_est):\n",
    "    J_tot = []\n",
    "    pt_arr = []\n",
    "    for pt_3d in pts_3d:\n",
    "        for i in range(3):\n",
    "            pt_arr.append(Proj_est[i][0]*pt_3d[0] + Proj_est[i][1]*pt_3d[1] + Proj_est[i][2]*pt_3d[2] + Proj_est[i][3])\n",
    "    \n",
    "    \n",
    "        J = np.array([pt_3d[0]/pt_arr[2],pt_3d[1]/pt_arr[2],pt_3d[2]/pt_arr[2],1/pt_arr[2],0,0,0,0,(-pt_arr[0]*pt_3d[0])/(pt_arr[2]*pt_arr[2]),(-pt_arr[0]*pt_3d[1])/(pt_arr[2]*pt_arr[2]),(-pt_arr[0]*pt_3d[2])/(pt_arr[2]*pt_arr[2]),-1/(pt_arr[2]*pt_arr[2]),\n",
    "                     0,0,0,0,pt_3d[0]/pt_arr[2],pt_3d[1]/pt_arr[2],pt_3d[2]/pt_arr[2],1/pt_arr[2],(-pt_arr[1]*pt_3d[0])/(pt_arr[2]*pt_arr[2]),(-pt_arr[1]*pt_3d[1])/(pt_arr[2]*pt_arr[2]),(-pt_arr[1]*pt_3d[2])/(pt_arr[2]*pt_arr[2]),-1/(pt_arr[2]*pt_arr[2])])\n",
    "        J_tot.append(J)\n",
    "    return np.array(J_tot).reshape(200,12)\n",
    "\n",
    "def gaussNewton(pts_2d, orig_pts_2d, pts_3d, Proj_est):\n",
    "    sum_sq_error = 10000\n",
    "    while True: \n",
    "        prev_error = sum_sq_error\n",
    "        pts_2d = [] \n",
    "        J = []\n",
    "        for i in range(len(pts_3d)) :\n",
    "            pt_2d = np.matmul(Proj_est, pts_3d[i])\n",
    "            pts_2d.append(pt_2d/pt_2d[2])\n",
    "            \n",
    "        sum_sq_error,error = get_err(orig_pts_2d, pts_2d)\n",
    "        print(\"squared sum error:\", sum_sq_error)\n",
    "        \n",
    "        if(abs(sum_sq_error - prev_error) < 0.0001):\n",
    "            break\n",
    "\n",
    "        \n",
    "        J =  getJ(pts_3d, Proj_est)\n",
    "        e = np.matmul(J.T, error.reshape(200,1)) \n",
    "        \n",
    "        JTJ = np.linalg.pinv(np.matmul(J.T, J)) \n",
    "    \n",
    "        delP = JTJ@e\n",
    "        delP = delP.reshape(3,4)\n",
    "        Proj_est = Proj_est + delP\n",
    "\n",
    "        return Proj_est\n",
    "Proj_est = gaussNewton(pts_2d,orig_pts_2d, pts_3d,Proj_est)\n",
    "\n",
    "print(\"Predicted projection matrix: \\n\")\n",
    "print(Proj_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
